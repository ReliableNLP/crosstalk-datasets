

# CROSSTALK-DATASETS

🤗 我们提供了一个中文相声和小品相关的数据集，并使用Seq2Seq，GPT，UniLM，GPT3分别测试了其在相声生成上的效果，通过Belu和distinct衡量了每种模型生成的效果，并且抽选了15位被试进行模型生成段落效果的排序（真实样本，RNN，GPT，UniLM，GPT3），此处提供我们base方案的各种评估指标，以及我们使用的训练集与测试集，还有部分的原始数据（如需全部，请联系我们）。



------



### 1.1. 数据集概况

| 篇章统计                                     | 数值 |
| -------------------------------------------- | ---- |
| 单口相声数量                                 | 170  |
| 对口相声数量                                 | 3692 |
| 群口相声数量                                 | 259  |
| 小品数量                                     | 5255 |
| 纯对话文本数量(包括对口，群口，纯对话的小品) | 4769 |
| 全文本数量                                   | 9376 |



| 数值统计              | 数值     |
| --------------------- | -------- |
| 数据集全字数          | 16809801 |
| 数据集全句数          | 676883   |
| 长句数（长度大于128） | 9039     |
| 短句数（长度小于24）  | 456465   |
| 句长中位数            | 16       |
| 篇章平均句子数        | 72       |





------



### 1.2. 示例数据集

| 路径                | 描述                 |
| ------------------- | -------------------- |
| demo_data/GPT_Train | base方案训练时的语料 |
| demo_data/ORI_Data  | 抽样出的原始语料格式 |

**meta格式说明：**

```
{
		"isAllDialog":true,                                       #是否为纯对话格式
		"charSize":526,                                           #本篇字数
		"filePath":"u399dy/蔡少芬李菁相声《学说普通话》台词完整版",     #相对路径
		"roles":[                                                 #角色
			"李菁:",
			"蔡少芬:"
		],
		"sentenceSize":25,                                        #句子数
		"source":"https://www.399dy.com/xiangsheng/11176.html",   #来源网站
		"idx":28,                                                 #索引
		"title":"蔡少芬李菁相声《学说普通话》台词完整版",               #篇章标题
		"type":"对口相声"                                          #类型
	},
```

**文本内格式实例：**

```
甲:现在的商业都讲究实事求是，公约上写着:“百问不烦，百拿不厌。”
乙:那是呀!
甲:旧社会做买卖就不一样，宣传得蛮好，实际净骗人，门口都写两块大牌子。
乙:写的什么?
甲:写着“货真价实，公平交易”。
乙:写得蛮好看!
甲:实际是货不真，价不实，大秤买，小秤卖，想尽一切办法多赚钱。大买卖讲究宣传，门口弄一份儿洋鼓洋号吹吹打打。还有的在电台登广告。广告都这样。
乙:您给学学。
甲:“各位先生，各位女士，早晨起来您不喝茶吗?您要想喝好茶叶的话，报告您一个好消息，××茶庄备有专人到南省产茶名区，采办各种红绿花茶，加花熏制，西湖龙井，铁叶儿大方，清香适口，气味芬芳，馈送亲友最为相宜。他家的地址:××大街往北路西一百七十三号，电话三局六二九四号。”
乙:是这样儿!
甲:这是那时候的大买卖。小买卖儿可报不起，做一天买卖连本带利将够一家子吃饭的，花不起广告费呀。像卖烤地瓜的也这么登广告就不行了。
乙:是吗?
甲:那稿子念起来也不受听啊!不信我给您念念。
乙:好。
```



------



### 1.3. base方案评估指标

|       | BLEU2(字) | BLEU4(字) | dist_1 | dist_2 |
| ----- | --------- | --------- | ------ | ------ |
| Seq2Seq   | 0.12 | 0.01 | 90.46 | 78.15 |
| GPT   | 6.01      | 2.19      |    91.27    | 83.98 |
| GPT3  | 7.42 | 2.48 | 82.94 | 75.96 |
| UniLM | 6.64 | 2.65 | 90.37 | 74.13 |

*TIP:所有的生成任务都没有加重复惩罚。*



**人工检验方式：**

截取50篇相声的前10句作为输入，有历史记忆的生成后10句，一共20句作为一个评估对象。

将每个篇章的Seq2Seq,GPT,GPT3,UniLM生成的句子拼接在输入句后面，合上原始篇章的20句，一共5个评估对象作为一个评估单元。

挑选了不同职业，不同地域，不同年龄，不同性别的14名被试，告诉他们需要对每个评估对象进行评价（0-不好，1-好），然后对每个评估单元中的5个评估对象由好到不好的顺序进行排序。被试被告知每个评估对象都是由不同的模型生成的。

最终我们得到每个模型的平均认可度 **(得到好的个数/总个数)** 分别为：

| 原始篇章 | UniLM | GPT3  | GPT   | Seq2Seq   |
| -------- | ----- | ----- | ----- | ----- |
| 89.14    | 46.14 | 45.14 | 30.57 | 16.14 |

每个模型的平均排序得分分别为：

| 原始篇章 | UniLM  | GPT3   | GPT    | Seq2Seq   |
| -------- | ------ | ------ | ------ | ----- |
| 222.07   | 151.71 | 147.64 | 126.07 | 102.5 |


fleiss_kappa : 0.3657753225075188

------



### 1.4.base方案



GPT使用的预训练模型：

https://huggingface.co/thu-coai/CDial-GPT_LCCC-base

GPT使用的训练代码：

https://github.com/yangjianxin1/GPT2-chitchat

GPT3地址（需自行申请）：

https://beta.openai.com/

UniLM的地址：

https://github.com/YunwenTechnology/Unilm

Seq2Seq的地址：

https://github.com/IBM/pytorch-seq2seq

